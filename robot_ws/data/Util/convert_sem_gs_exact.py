#!/usr/bin/env python3
"""
ä½¿ç”¨ç²¾ç¢º RGB æ˜ å°„è½‰æ› Final_SEM_GS.ply
é€™å€‹ç‰ˆæœ¬ç›´æ¥ä½¿ç”¨å¯¦éš›é¡è‰²åˆ°é¡åˆ¥çš„ç²¾ç¢ºæ˜ å°„
"""

import numpy as np
import argparse
import os
import sys
from plyfile import PlyData
import json


def convert_with_exact_mapping(ply_path, output_path, mapping_path):
    """ä½¿ç”¨ç²¾ç¢ºé¡è‰²æ˜ å°„è½‰æ›"""
    
    print("=" * 70)
    print(f"ğŸ“‚ è®€å–èªç¾© PLY æ–‡ä»¶: {ply_path}")
    print("=" * 70)
    
    # 1. è®€å– PLY
    ply_data = PlyData.read(ply_path)
    vertex_data = ply_data['vertex'].data
    num_points = len(vertex_data)
    print(f"âœ… æˆåŠŸè®€å– {num_points:,} å€‹é»")
    
    # 2. æå– XYZ
    points = np.zeros((num_points, 3), dtype=np.float32)
    points[:, 0] = vertex_data['x']
    points[:, 1] = vertex_data['y']
    points[:, 2] = vertex_data['z']
    print(f"âœ… æå– XYZ åº§æ¨™: {points.shape}")
    
    # 3. æå– RGB
    sh_dc = np.zeros((num_points, 3), dtype=np.float32)
    sh_dc[:, 0] = vertex_data['f_dc_0']
    sh_dc[:, 1] = vertex_data['f_dc_1']
    sh_dc[:, 2] = vertex_data['f_dc_2']
    
    C0 = 0.28209479177387814
    rgb = sh_dc * C0 + 0.5
    rgb = np.clip(rgb, 0, 1)
    print(f"âœ… å¾çƒè«§ä¿‚æ•¸è½‰æ› RGB: {rgb.shape}")
    
    # 4. è®€å–ç²¾ç¢ºæ˜ å°„
    print(f"\nğŸ“‚ è®€å–ç²¾ç¢ºé¡è‰²æ˜ å°„: {mapping_path}")
    with open(mapping_path, 'r') as f:
        mapping_data = json.load(f)
    
    color_mappings = mapping_data['color_mapping']
    print(f"âœ… è¼‰å…¥ {len(color_mappings)} å€‹é¡è‰²æ˜ å°„")
    
    # 5. å»ºç«‹ RGB -> é¡åˆ¥ ID çš„æ˜ å°„
    rgb_to_id = {}
    id_to_name = {}
    
    for i, mapping in enumerate(color_mappings):
        rgb_key = tuple(np.round(mapping['rgb'], 3))
        category = mapping['category']
        rgb_to_id[rgb_key] = i
        id_to_name[i] = category
    
    print(f"\nğŸ¨ é–‹å§‹ç²¾ç¢ºé¡è‰²åŒ¹é…ï¼ˆRGB ç©ºé–“ï¼Œå®¹å·® 0.001ï¼‰...")
    
    # 6. åŒ¹é…æ¯å€‹é»ï¼ˆä½¿ç”¨å®¹å·®ï¼‰
    semantic_ids = np.zeros(num_points, dtype=np.int32)
    
    # æº–å‚™æ‰€æœ‰æ˜ å°„é¡è‰²çš„æ•¸çµ„
    mapping_rgbs = np.array([m['rgb'] for m in color_mappings])  # (16, 3)
    
    matched_count = 0
    batch_size = 100000
    
    for batch_start in range(0, num_points, batch_size):
        batch_end = min(batch_start + batch_size, num_points)
        batch_rgb = rgb[batch_start:batch_end]  # (batch_size, 3)
        
        # è¨ˆç®—æ‰¹æ¬¡ä¸­æ¯å€‹é»åˆ°æ‰€æœ‰æ˜ å°„é¡è‰²çš„è·é›¢
        # batch_rgb: (batch_size, 3), mapping_rgbs: (16, 3)
        # distances: (batch_size, 16)
        distances = np.sqrt(np.sum((batch_rgb[:, np.newaxis, :] - mapping_rgbs[np.newaxis, :, :]) ** 2, axis=2))
        
        # æ‰¾åˆ°æœ€è¿‘çš„é¡è‰²
        closest_indices = np.argmin(distances, axis=1)  # (batch_size,)
        min_distances = np.min(distances, axis=1)  # (batch_size,)
        
        # åˆ†é… ID
        semantic_ids[batch_start:batch_end] = closest_indices
        
        # çµ±è¨ˆåŒ¹é…ï¼ˆè·é›¢å°æ–¼ 0.001 è¦–ç‚ºç²¾ç¢ºåŒ¹é…ï¼‰
        matched_count += np.sum(min_distances < 0.001)
        
        if batch_end % 500000 == 0 or batch_end == num_points:
            print(f"   è™•ç†é€²åº¦: {batch_end}/{num_points} ({100*batch_end/num_points:.1f}%)")
    
    print(f"   âœ… å®ŒæˆåŒ¹é…")
    print(f"   ç²¾ç¢ºåŒ¹é…ç‡: {100*matched_count/num_points:.2f}% ({matched_count:,}/{num_points:,})")
    print(f"   è¿‘ä¼¼åŒ¹é…: æ‰€æœ‰é»éƒ½è¢«åˆ†é…åˆ°æœ€æ¥è¿‘çš„é¡åˆ¥")
    
    # 7. çµ±è¨ˆé¡åˆ¥åˆ†ä½ˆ
    unique_ids = np.unique(semantic_ids)
    print(f"\nâœ… èªç¾©åˆ†é¡å®Œæˆ:")
    print(f"   - èªç¾© ID ç¯„åœ: [{semantic_ids.min()}, {semantic_ids.max()}]")
    print(f"   - æª¢æ¸¬åˆ°çš„é¡åˆ¥æ•¸: {len(unique_ids)}")
    
    id_counts = np.bincount(semantic_ids)
    print(f"   - é¡åˆ¥åˆ†ä½ˆ:")
    for i, count in enumerate(id_counts):
        if count > 0:
            pct = 100 * count / num_points
            class_name = id_to_name.get(i, 'unknown')
            print(f"      ID {i:2d} ({class_name:15s}): {count:7,} é» ({pct:5.2f}%)")
    
    # 8. ä¿å­˜ NPZ
    save_dict = {
        'means3D': points,
        'pts': points,
        'pan': semantic_ids,
        'semantic_ids': semantic_ids,
        'rgb': rgb
    }
    
    np.savez_compressed(output_path, **save_dict)
    print(f"\nâœ… æˆåŠŸä¿å­˜ NPZ æ–‡ä»¶: {output_path}")
    
    # 9. å‰µå»ºå…ƒæ•¸æ“š JSON
    json_output = output_path.replace('.npz', '_meta.json')
    segments_info = []
    for idx, name in id_to_name.items():
        if idx < len(id_counts) and id_counts[idx] > 0:
            segments_info.append({
                "id": int(idx),
                "category_name": name,
                "class": name,
                "point_count": int(id_counts[idx])
            })
    
    output_json = {"segments_info": segments_info}
    with open(json_output, 'w') as f:
        json.dump(output_json, f, indent=2)
    
    print(f"âœ… ä¿å­˜èªç¾©å…ƒæ•¸æ“š: {json_output}")
    
    # 10. é©—è­‰
    print("\n" + "=" * 70)
    print("ğŸ“‹ é©—è­‰ä¿å­˜çš„ NPZ æ–‡ä»¶:")
    print("=" * 70)
    
    loaded = np.load(output_path)
    for key in loaded.keys():
        data = loaded[key]
        print(f"   â€¢ {key:20s}: shape={data.shape}, dtype={data.dtype}")
    
    print("\n" + "=" * 70)
    print("âœ… è½‰æ›å®Œæˆï¼")
    print("=" * 70)
    
    return True


def main():
    parser = argparse.ArgumentParser(description='ä½¿ç”¨ç²¾ç¢º RGB æ˜ å°„è½‰æ› Final_SEM_GS.ply')
    parser.add_argument('--input_ply', default='/home/acm118/robot_ws/data/Util/Final_GS.ply', help='è¼¸å…¥ PLY æ–‡ä»¶')
    parser.add_argument('--output_npz', default='/home/acm118/robot_ws/data/Util/Final_GS_converted.npz', help='è¼¸å‡º NPZ æ–‡ä»¶')
    parser.add_argument('--mapping', '-m', default='actual_color_mapping.json', 
                       help='é¡è‰²æ˜ å°„ JSON æ–‡ä»¶ï¼ˆé»˜èª: actual_color_mapping.jsonï¼‰')
    
    args = parser.parse_args()
    
    success = convert_with_exact_mapping(args.input_ply, args.output_npz, args.mapping)
    sys.exit(0 if success else 1)


if __name__ == '__main__':
    main()
